# 🚨 J-SafeGuard
### Java 기반 재난 탐사 및 통합 관제 로봇 시스템  
*(SML 기반 의사결정 + STT/TTS 음성 커뮤니케이션)*

---

## 1. 프로젝트 개요

J-SafeGuard는 화재, 유독 가스 누출, 붕괴 위험 등 **재난 현장에 구조대원보다 먼저 진입하는 탐사 로봇**과  
이를 제어·관제하는 **Java 기반 데스크톱 통합 관제 시스템**을 구현하는 프로젝트이다.

웹 기반 관제가 아닌 **Java Desktop + TCP Socket 구조**를 채택하여,
- 불안정한 현장 네트워크 환경에서도
- 낮은 지연과 안정적인 제어
- 실시간 센서·영상 데이터 처리

를 목표로 설계하였다.

---

## 2. 프로젝트 목표

1. **원격 로봇 제어**
   - 조이스틱 기반 실시간 이동 제어
2. **재난 현장 정보 수집 및 시각화**
   - LiDAR 기반 맵
   - 센서 데이터
   - 영상 스트리밍
3. **SML 기반 구조 의사결정**
   - 센서 데이터 종합 판단
   - 로봇 행동 및 사용자 안내 메시지 생성
4. **STT/TTS 기반 생존자 커뮤니케이션**
   - 생존자 음성 인식(STT)
   - 구조대원 음성 안내(TTS)
5. **사후 분석을 위한 데이터 기록**
   - 시간대별 센서 로그
   - 영상 리플레이

---

## 3. 전체 시스템 아키텍처

### 3-Tier 구조 + AI/음성 흐름
```
  [ 로봇 (Python) ]
  ├─ 모터 / 이동 제어
  ├─ 센서 데이터 수집
  ├─ LiDAR 맵 데이터
  ├─ 영상 송신
  ├─ STT : 생존자 음성 → 텍스트
  └─ TTS : 관제 메시지 → 음성 출력
  │ TCP Socket (JSON)
  ▼
  [ 중앙 서버 (Java 17) ]
  ├─ 로봇 데이터 수신/파싱
  ├─ 센서·이벤트 DB 저장
  ├─ 관제 클라이언트 중계
  └─ SML 호출 (의사결정)
  │ TCP Socket
  ▼
  [ 관제 PC (Java Desktop) ]
  ├─ 조이스틱 기반 로봇 제어
  ├─ LiDAR 맵 시각화
  ├─ 센서 대시보드
  ├─ 채팅형 GUI (STT/TTS 로그)
  └─ 영상/데이터 리플레이
```

> ⚠ 중앙 서버는 **Spring Boot가 아닌 Java 17 기반 커스텀 TCP 서버**  
> 실시간성과 제어 안정성을 우선한 설계

---

## 4. 기술 스택

### 🤖 Robot (Edge)
- Language: **Python**
- 기능:
  - 이동 제어
  - 센서 데이터 수집
  - 영상 송신
  - STT 입력 처리
  - TTS 음성 출력
- 통신: **TCP Socket**

---

### 🧠 AI 의사결정
- Model: **LLaMA 8B**
- 분류: **SML (8B급 소형 언어 모델)**
- 방식:
  - 구조 시나리오 기반 데이터 파인튜닝
- 역할:
  - 센서 데이터 종합 해석
  - 위험 단계 판단
  - 로봇 행동 결정
  - 사용자/GUI 메시지 생성

---

### 🖥 Central Server
- Language: **Java 17**
- 역할:
  - 로봇 ↔ 관제 PC 데이터 중계
  - 센서 데이터 파싱
  - DB 저장
  - SML 호출 및 결과 분배
- 특징:
  - ServerSocket 기반
  - 실시간 처리 중심 구조

---

### 🎛 Control Client (Desktop)
- Language: **Java**
- GUI: **Java Swing / AWT**
- 기능:
  - 로봇 조종
  - 지도·센서 시각화
  - 채팅형 STT/TTS 로그 표시
  - 영상 및 센서 데이터 리플레이

---

### 🗄 Database
- RDBMS: **MySQL**
- 저장 대상:
  - 시간대별 센서 데이터
  - 이벤트 로그
  - 영상 메타데이터

---

## 5. 센서 구성 및 구현 현황

### ✅ 구현 완료

| 센서 | 설명 |
|---|---|
| LiDAR | 실시간 맵 데이터 수신 및 GUI 시각화 |
| Camera | 영상 수신 및 저장 |
| 기본 환경 센서 | 데이터 수신 가능 (보정 필요) |

### ⚠ 부분 구현 / 미구현

| 센서 | 상태 | 사유 |
|---|---|---|
| 일부 복합 센서 | 미완 | 하드웨어/드라이버 제약 |
| 고급 AI 인식 센서 | 미구현 | 연산 자원 및 시간 제한 |

---

## 6. SML 기반 구조요원 에이전트

### 입력
- 센서 데이터 (가스, 먼지, 온도 등)
- 이벤트 정보 (생존자 감지 등)
- STT 결과 텍스트

### 출력
- `hazard_level` : NORMAL / MEDIUM / HIGH / CRITICAL
- `robot_action` : MOVE / STOP / WAIT / SEARCH / ALERT
- `voice_instruction` : 생존자 안내 음성 문장
- `gui_message` : 관제 GUI 표시 메시지

> 실시간 제어 AI가 아닌 **의사결정 보조 SML**로 사용

---

## 7. STT / TTS 기반 커뮤니케이션

### STT (Speech-to-Text)
- 생존자 음성 → 텍스트 변환
- 변환 결과를 **관제 GUI 채팅 로그에 표시**
- SML 입력 데이터로 활용 가능

### TTS (Text-to-Speech)
- 관제 GUI에서 입력한 문장 → 로봇 측 음성 출력
- 동시에 GUI 채팅 로그에 표시

---

## 8. 팀 구성 및 역할 (5인)

### PM / Server / AI
**박형석**
- 프로젝트 총괄
- 시스템 초기 세팅 및 작업 분배
- 잔버그 수정
- Java 서버 구조 설계
- LLaMA 8B(SML) 학습 및 의사결정 로직 설계

### Desktop Client
**김도경**
- 조이스틱 기반 로봇 제어
- LiDAR 맵 시각화
- 센서 소켓 연동
- 메인 관제 GUI 개발

### Desktop Client
**Victoria**
- 영상 리플레이 GUI
- DB 연동
- 시간대별 센서/영상 조회 화면 구현

### Database
**이의성**
- DB 스키마 설계
- 센서·영상 데이터 구조 정의
- 시간 기반 데이터 관리 설계

### Robot (Edge)
**조우진**
- Python 기반 로봇 제어
- 센서·영상 처리
- 이동 로직 구현

---

## 9. 한계 및 향후 개선

### 한계
- 모든 센서 완전 구현의 현실적 제약
- 네트워크 장애 대응 미흡

### 향후 개선
- Spring Boot 기반 관리/모니터링 서버 분리
- SML 판단 로직 고도화
- 센서 신뢰도 개선

📌 *본 프로젝트는 대학 프로젝트 및 학습 목적의 시스템입니다.*
